{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a dataset directory\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TOF18 Dataset from Indepth Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir_ToF = '/mnt/IRONWOLF1/ashkan/data/ToF-18K'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in os.listdir(image_dir_ToF):\n",
    "    if not image.endswith('_undistorted.jpg'):\n",
    "        # write in the file\n",
    "        print(image)\n",
    "        with open('toF18_split.txt', 'a') as f:\n",
    "            depth_path = os.path.join ('data', image).replace('.jpg', '_z16.png')\n",
    "            f.write(os.path.join(image) + ' ' + depth_path + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARKitScene dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "arkitScenes_path = '/mnt/IRONWOLF1/ashkan/data/ARKitScenes/upsampling'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_split_txt(split_file, th):\n",
    "    for scene in os.listdir(os.path.join(arkitScenes_path, split_file)):\n",
    "        for sample in os.listdir(os.path.join(arkitScenes_path, split_file, scene, 'highres_depth')):\n",
    "            # if gt depth missing points are less than 20% of the image\n",
    "            depth_path = os.path.join(arkitScenes_path, split_file, scene, 'highres_depth', sample)\n",
    "            depth = np.array(Image.open(depth_path))\n",
    "            missing = np.sum(depth == 0)\n",
    "            if missing / depth.size < th:\n",
    "                with open(f'arkit_split_{split_file}.txt', 'a') as f:\n",
    "                    f.write(os.path.join(scene, 'lowres_wide', sample) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for scene in os.listdir(os.path.join(arkitScenes_path, 'Validation')):\n",
    "#     for sample in os.listdir(os.path.join(arkitScenes_path, 'Validation', scene, 'highres_depth')):\n",
    "#         # if gt depth missing points are less than 20% of the image\n",
    "#         depth_path = os.path.join(arkitScenes_path, 'Validation', scene, 'highres_depth', sample)\n",
    "#         depth = np.array(Image.open(depth_path))\n",
    "#         missing = np.sum(depth == 0)\n",
    "#         if missing / depth.size < 0.1:\n",
    "#             with open(f'arkit_split_Validation.txt', 'a') as f:\n",
    "#                 line = f\"{os.path.join(scene, 'lowres_wide', sample)} {os.path.join(scene, 'downsampled_gt', sample)} \\n\"\n",
    "#                 f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_split_txt('Training', 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "# Create threads for each split_file and th combination\n",
    "threads = []\n",
    "threads.append(threading.Thread(target=gen_split_txt, args=('Validation', 0.1)))\n",
    "threads.append(threading.Thread(target=gen_split_txt, args=('Training', 0.1)))\n",
    "\n",
    "# Start the threads\n",
    "for thread in threads:\n",
    "    thread.start()\n",
    "\n",
    "# Wait for all threads to finish\n",
    "for thread in threads:\n",
    "    thread.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for scene in os.listdir(os.path.join(arkitScenes_path, 'Validation')):\n",
    "#     for sample in os.listdir(os.path.join(arkitScenes_path, 'Validation', scene, 'highres_depth')):\n",
    "#         print(sample)\n",
    "#         # if gt depth missing points are less than 20% of the image\n",
    "#         depth_path = os.path.join(arkitScenes_path, 'Validation', scene, 'highres_depth', sample)\n",
    "#         depth = np.array(Image.open(depth_path))\n",
    "#         missing = np.sum(depth == 0)\n",
    "#         if missing / depth.size < 0.2:\n",
    "#             with open('arkit_split_validation.txt', 'a') as f:\n",
    "#                 f.write(os.path.join(scene, 'lowres_wide', sample) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for scene in os.listdir(os.path.join(arkitScenes_path, 'Training')):\n",
    "#     for sample in os.listdir(os.path.join(arkitScenes_path, 'Training', scene, 'highres_depth')):\n",
    "#         print(sample)\n",
    "#         # if gt depth missing points are less than 20% of the image\n",
    "#         depth_path = os.path.join(arkitScenes_path, 'Training', scene, 'highres_depth', sample)\n",
    "#         depth = np.array(Image.open(depth_path))\n",
    "#         missing = np.sum(depth == 0)\n",
    "#         # if missing / depth.size < 0.2:\n",
    "#             with open('arkit_split_training.txt', 'a') as f:\n",
    "#                 f.write(os.path.join(scene, 'lowres_wide', sample) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matterport3D dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files_path = './Matterport3D/test_file_list_normal.txt'\n",
    "train_files_path = './Matterport3D/train_file_list_normal.txt'\n",
    "\n",
    "Matterport3D = '/mnt/IRONWOLF2/yiqinzhao/Matterport3D/v1/scans/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_split(file, split):\n",
    "    # Initialize dictionaries to store color and depth paths by ID\n",
    "    color_images = {}\n",
    "    depth_images = {}\n",
    "\n",
    "    # Read the file and populate the dictionaries\n",
    "    with open(file, 'r') as input_file:\n",
    "        for line in input_file:\n",
    "            parts = line.strip().split(' ')\n",
    "            # Original paths\n",
    "            color_path = parts[0].replace('/path/to/your/', '')\n",
    "            depth_path = parts[1].replace('/path/to/your/', '')\n",
    "\n",
    "            # Split paths to reformat them\n",
    "            color_parts = color_path.split('/')\n",
    "            depth_parts = depth_path.split('/')\n",
    "            \n",
    "            \n",
    "\n",
    "            # Reformat paths by moving the ID to the front and replacing folder names\n",
    "            new_color_path = f\"{color_parts[1]}/undistorted_color_images/{'/'.join(color_parts[2:])}\"\n",
    "            new_depth_path = f\"{depth_parts[1]}/undistorted_depth_images/{'/'.join(depth_parts[2:])}\"\n",
    "\n",
    "            # Extract IDs\n",
    "            color_id = color_parts[1]\n",
    "            depth_id = depth_parts[1]\n",
    "            \n",
    "\n",
    "            # Append paths to their respective lists within the dictionaries\n",
    "            if color_id not in color_images:\n",
    "                color_images[color_id] = []\n",
    "            color_images[color_id].append(new_color_path)\n",
    "            \n",
    "            if depth_id not in depth_images:\n",
    "                depth_images[depth_id] = []\n",
    "            depth_images[depth_id].append(new_depth_path)\n",
    "            \n",
    "            depth_path = os.path.join(Matterport3D, 'Training', scene, 'highres_depth', sample)\n",
    "            depth = np.array(Image.open(depth_path))\n",
    "            missing = np.sum(depth == 0)\n",
    "\n",
    "    # Write the matched paths to the output file, pairing each color with its corresponding depth image\n",
    "    output_file_path = f'./Matterport3D_{split}_split.txt'\n",
    "    with open(output_file_path, 'w') as output_file:\n",
    "        for id in color_images:\n",
    "            if id in depth_images:\n",
    "                # Iterate through both lists and pair images by their index\n",
    "                for color_path, depth_path in zip(color_images[id], depth_images[id]):\n",
    "                    # if gt depth missing points are less than 20% of the image\n",
    "                #   depth_path = os.path.join(arkitScenes_path, 'Validation', scene, 'highres_depth', sample)\n",
    "        #         depth = np.array(Image.open(depth_path))\n",
    "        #         missing = np.sum(depth == 0)\n",
    "        #         if missing / depth.size < 0.2:\n",
    "        #             with open('arkit_split_validation.txt', 'a') as f:\n",
    "        #                 f.write(os.path.join(scene, 'lowres_wide', sample) + '\\n')\n",
    "                    output_file.write(f\"{color_path} {depth_path}\\n\")\n",
    "\n",
    "    return output_file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_split(test_files_path, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "create_split(train_files_path, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
